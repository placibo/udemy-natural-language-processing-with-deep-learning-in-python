{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section -2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/placibo/udemy-natural-language-processing-with-deep-learning-in-python/blob/master/Section_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIEj7zbrTstq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function,division\n",
        "from future.utils import iteritems\n",
        "from builtins import range"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h2HnXtXUDOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg2oPirZUIk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwdZWH1yY5B0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_vectors = KeyedVectors.load_word2vec_format(\n",
        "    './GoogleNews-vectors-negative300.bin.gz',binary=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3npf-TuZEwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_analogies(w1,w2,w3):\n",
        "  r = word_vectors.most_similar(positive=[w1,w3],negative=[w2])\n",
        "  print(\"%s - %s = %s - %s\" % (w1,w2,r[0][0],w3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr73PiPRaeQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nearest_neighbors(w):\n",
        "  r = word_vectors.most_similar(positive=[w])\n",
        "  print(\"neighbour of: %s\" %w)\n",
        "  for word, score in r:\n",
        "    print(\"\\t%s\" % word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8LKi8KybTOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_analogies('king','man','woman')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o8AdO3PcALU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nearest_neighbors('Harvard')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwjepA89gweE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5qEzC1cipR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fa6d2799-afca-4757-a5e3-71abf8dc4361"
      },
      "source": [
        "!wget https://www.cs.umb.edu/~smimarog/textmining/datasets/r8-train-all-terms.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-28 15:52:08--  https://www.cs.umb.edu/~smimarog/textmining/datasets/r8-train-all-terms.txt\n",
            "Resolving www.cs.umb.edu (www.cs.umb.edu)... 158.121.106.224\n",
            "Connecting to www.cs.umb.edu (www.cs.umb.edu)|158.121.106.224|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3354424 (3.2M) [text/plain]\n",
            "Saving to: ‘r8-train-all-terms.txt’\n",
            "\n",
            "r8-train-all-terms. 100%[===================>]   3.20M  4.09MB/s    in 0.8s    \n",
            "\n",
            "2019-08-28 15:52:10 (4.09 MB/s) - ‘r8-train-all-terms.txt’ saved [3354424/3354424]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMy4Yyjfj2zE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "eb8a613a-8035-44de-ed6b-ba1c6fe0d329"
      },
      "source": [
        "!wget https://www.cs.umb.edu/~smimarog/textmining/datasets/r8-test-all-terms.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-28 15:52:13--  https://www.cs.umb.edu/~smimarog/textmining/datasets/r8-test-all-terms.txt\n",
            "Resolving www.cs.umb.edu (www.cs.umb.edu)... 158.121.106.224\n",
            "Connecting to www.cs.umb.edu (www.cs.umb.edu)|158.121.106.224|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1195261 (1.1M) [text/plain]\n",
            "Saving to: ‘r8-test-all-terms.txt’\n",
            "\n",
            "\rr8-test-all-terms.t   0%[                    ]       0  --.-KB/s               \rr8-test-all-terms.t   7%[>                   ]  88.00K   313KB/s               \rr8-test-all-terms.t  50%[=========>          ] 584.00K  1.19MB/s               \rr8-test-all-terms.t 100%[===================>]   1.14M  1.94MB/s    in 0.6s    \n",
            "\n",
            "2019-08-28 15:52:14 (1.94 MB/s) - ‘r8-test-all-terms.txt’ saved [1195261/1195261]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yidANvVYtVO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEC7w6ytto2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c066bad2-4185-4e32-8ac2-1cb1cf369d93"
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGYFj_cIj-wJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('./r8-test-all-terms.txt',header=None,sep='\\t')\n",
        "train = pd.read_csv('r8-train-all-terms.txt',header=None,sep='\\t')\n",
        "train.columns = ['label','content']\n",
        "test.columns = ['label','content']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgjTlf5yodAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GloveVectorizer:\n",
        "  def __init__(self):\n",
        "    print('Loading word vectors')\n",
        "    word2vec = {}\n",
        "    embedding = []\n",
        "    idx2word = []\n",
        "    with open('glove.6B.50d.txt') as f:\n",
        "      for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vec = np.asarray(values[1:],dtype='float32')\n",
        "        word2vec[word] = vec\n",
        "        embedding.append(vec)\n",
        "        idx2word.append(word)\n",
        "    print('Found %s word vectors.' % len(word2vec))\n",
        "    \n",
        "    self.word2vec = word2vec\n",
        "    self.embedding = np.array(embedding)\n",
        "    self.word2idx = {v:k for k,v in enumerate(idx2word)}\n",
        "    self.V, self.D = self.embedding.shape\n",
        "   \n",
        "  def fit(self,data):\n",
        "    pass\n",
        "  \n",
        "  def transform(self,data):\n",
        "    X = np.zeros((len(data),self.D))\n",
        "    n=0\n",
        "    emptycount = 0\n",
        "    for sentence in data:\n",
        "      tokens = sentence.lower().split()\n",
        "      vecs = []\n",
        "      for word in tokens:\n",
        "        if word in self.word2vec:\n",
        "          vec = self.word2vec[word]\n",
        "          vecs.append(vec)\n",
        "      \n",
        "      if len(vecs) > 0:\n",
        "        vecs = np.array(vecs)\n",
        "        X[n] = vecs.mean(axis=0)\n",
        "      else:\n",
        "        emptycount += 1\n",
        "      n += 1\n",
        "    print(\"Number of samples with no words found: %s / %s\" % (emptycount,len(data)))\n",
        "    return X\n",
        "  \n",
        "  def fit_transform(self,data):\n",
        "    self.fit(data)\n",
        "    return self.transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPWOciBy0hQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Word2VecVectorizer:\n",
        "  def __init__(self):\n",
        "    print('Loading in word vectors...')\n",
        "    self.word_vectors = KeyedVectors.load_word2vec_format(\n",
        "    './GoogleNews-vectors-negative300.bin.gz',binary=True\n",
        "    )\n",
        "    print(\"Finished loading in word vectors\")\n",
        "    \n",
        "  def fit(self,data):\n",
        "    pass\n",
        "  \n",
        "  def transform(self,data):\n",
        "    v = self.word_vectors.get_vector('king')\n",
        "    self.D = v.shape[0]\n",
        "    \n",
        "    X = np.zeros((len(data),self.D))\n",
        "    n=0\n",
        "    emptycount = 0\n",
        "    for sentence in data:\n",
        "      tokens = sentence.split()\n",
        "      vecs = []\n",
        "      m=0\n",
        "      for word in tokens:\n",
        "        try:\n",
        "          vec = self.word_vectors.get_vector(word)\n",
        "          vecs.append(vec)\n",
        "          m += 1\n",
        "        except KeyError:\n",
        "          pass\n",
        "      if len(vecs) > 0:\n",
        "        vecs = np.array(vecs)\n",
        "        X[n] = vecs.mean(axis=0)\n",
        "      else:\n",
        "        emptycount += 1\n",
        "      n += 1\n",
        "    print(\"Number of samples with no word found %s / %s\" % (emptycount,len(data)))\n",
        "    return X\n",
        "  \n",
        "  def fit_transform(self,data):\n",
        "    self.fit(data)\n",
        "    return self.transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9NOZq7D3KiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = Word2VecVectorizer()\n",
        "Xtrain = vectorizer.fit_transform(train.content)\n",
        "Ytrain = train.label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-YaYmJ1461Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtest = vectorizer.fit_transform(test.content)\n",
        "Ytest = test.label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5g37b8N8jKZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b3136829-4559-4a87-f7a6-9502f932bf2b"
      },
      "source": [
        "model = RandomForestClassifier(n_estimators=200)\n",
        "model.fit(Xtrain,Ytrain)\n",
        "print(\"train score: \",model.score(Xtrain,Ytrain))\n",
        "print(\"test score: \",model.score(Xtest,Ytest))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train score:  0.9992707383773929\n",
            "test score:  0.9392416628597533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1TeZlDP8_r2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6643a10b-06b7-4d39-92b7-4f54ed4fa9e7"
      },
      "source": [
        "vectorizer = GloveVectorizer()\n",
        "Xtrain = vectorizer.fit_transform(train.content)\n",
        "Ytrain = train.label"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors\n",
            "Found 400000 word vectors.\n",
            "Number of samples with no words found: 0 / 5485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KbzDJww-MyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13a4158a-6ef8-43e4-8490-41319befe63a"
      },
      "source": [
        "Xtest = vectorizer.fit_transform(test.content)\n",
        "Ytest = test.label"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples with no words found: 0 / 2189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0xpCuSf-M1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "51783fd4-feb8-4338-980b-78b5acc4aeac"
      },
      "source": [
        "model = RandomForestClassifier(n_estimators=200)\n",
        "model.fit(Xtrain,Ytrain)\n",
        "print(\"train score: \",model.score(Xtrain,Ytrain))\n",
        "print(\"test score: \",model.score(Xtest,Ytest))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train score:  0.9992707383773929\n",
            "test score:  0.9346733668341709\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}